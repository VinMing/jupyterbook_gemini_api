{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用嵌入训练文本分类器\n",
    "## 概述\n",
    "在本笔记本中，您将学习使用 Gemini API 生成的嵌入来训练模型，该模型可以根据主题对不同类型的新闻组帖子进行分类。\n",
    "\n",
    "在本教程中，您将训练一个分类器来预测新闻组帖子属于哪个类别。\n",
    "\n",
    "## 前提条件\n",
    "您可以在 Google Colab 中运行此快速入门。 \n",
    "\n",
    "要在您自己的开发环境中完成本快速入门，请确保您的环境满足以下要求： \n",
    "- Python 3.9+ \n",
    "- 安装 jupyter 以运行笔记本\n",
    "\n",
    "## 安装\n",
    "首先，下载并安装 Gemini API Python 库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google.generativeai in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (0.3.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google.generativeai) (0.4.0)\n",
      "Requirement already satisfied: google-auth in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google.generativeai) (2.25.2)\n",
      "Requirement already satisfied: google-api-core in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google.generativeai) (2.15.0)\n",
      "Requirement already satisfied: protobuf in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google.generativeai) (4.23.4)\n",
      "Requirement already satisfied: tqdm in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google.generativeai) (4.66.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-ai-generativelanguage==0.4.0->google.generativeai) (1.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-api-core->google.generativeai) (1.62.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-api-core->google.generativeai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-auth->google.generativeai) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-auth->google.generativeai) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-auth->google.generativeai) (4.9)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google.generativeai) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google.generativeai) (1.60.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth->google.generativeai) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install google.generativeai \n",
    "# keras tensorflow\n",
    "## !pip install -U -q google.colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tqdm\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import google.generativeai as genai\n",
    "import google.ai.generativelanguage as glm\n",
    "\n",
    "# Used to securely store your API key\n",
    "# from google.colab import userdata\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import layers\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import sklearn.metrics as skmetrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取 API 密钥\n",
    "在使用 Gemini API 之前，您必须先获取 API 密钥。如果您还没有密钥，请在 Google AI Studio 中一键创建密钥。\n",
    "\n",
    "在 Colab 中，将密钥添加到左侧面板“🔑”下的秘密管理器中。将其命名为 API_KEY。 获得 API 密钥后，将其传递给 SDK。您可以通过两种方式执行此操作：\n",
    "- 将密钥放入 GOOGLE_API_KEY 环境变量中（SDK 将自动从那里获取它）。\n",
    "- 将密钥传递给 genai.configure(api_key=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "# GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
    "GOOGLE_API_KEY = \"AIzaSyBityeJag9WTYwuZ75VJvqn3I4kzRm1Omo\"\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "要点：接下来，您将选择一个模型。任何嵌入模型都适用于本教程，但对于实际应用程序，选择特定模型并坚持使用非常重要。不同型号的输出互不兼容。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'embedContent' in m.supported_generation_methods:\n",
    "    print(m.name)\n",
    "\n",
    "# for m in genai.list_models():\n",
    "#   if 'generateContent' in m.supported_generation_methods:\n",
    "#     print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集\n",
    "[20 个新闻组文本数据集](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html)包含 20 个主题的 18,000 个新闻组帖子，分为训练集和测试集。训练和测试数据集之间的划分基于特定日期之前和之后发布的消息。在本教程中，您将使用训练和测试数据集的子集。您将预处理数据并将其组织到 Pandas 数据框中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "# View list of class names for dataset\n",
    "newsgroups_train.target_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是训练集中数据点的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = newsgroups_train.data[0].index('Lines')\n",
    "print(newsgroups_train.data[0][idx:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在您将开始预处理本教程的数据。删除任何敏感信息，例如姓名、电子邮件或文本的冗余部分（例如`“发件人：”`和`“\\n主题：”`）。将信息组织到 Pandas 数据框中，使其更具可读性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_newsgroup_data(newsgroup_dataset):\n",
    "  # Apply functions to remove names, emails, and extraneous words from data points in newsgroups.data\n",
    "  newsgroup_dataset.data = [re.sub(r'[\\w\\.-]+@[\\w\\.-]+', '', d) for d in newsgroup_dataset.data] # Remove email\n",
    "  newsgroup_dataset.data = [re.sub(r\"\\([^()]*\\)\", \"\", d) for d in newsgroup_dataset.data] # Remove names\n",
    "  newsgroup_dataset.data = [d.replace(\"From: \", \"\") for d in newsgroup_dataset.data] # Remove \"From: \"\n",
    "  newsgroup_dataset.data = [d.replace(\"\\nSubject: \", \"\") for d in newsgroup_dataset.data] # Remove \"\\nSubject: \"\n",
    "\n",
    "  # Cut off each text entry after 5,000 characters\n",
    "  newsgroup_dataset.data = [d[0:5000] if len(d) > 5000 else d for d in newsgroup_dataset.data]\n",
    "\n",
    "  # Put data points into dataframe\n",
    "  df_processed = pd.DataFrame(newsgroup_dataset.data, columns=['Text'])\n",
    "  df_processed['Label'] = newsgroup_dataset.target\n",
    "  # Match label to target name index\n",
    "  df_processed['Class Name'] = ''\n",
    "  for idx, row in df_processed.iterrows():\n",
    "    df_processed.at[idx, 'Class Name'] = newsgroup_dataset.target_names[row['Label']]\n",
    "\n",
    "  return df_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHAT car is this!?\\nNntp-Posting-Host: rac3.w...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SI Clock Poll - Final Call\\nSummary: Final ca...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PB questions...\\nOrganization: Purdue Univers...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: Weitek P9000 ?\\nOrganization: Harris Comp...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: Shuttle Launch Question\\nOrganization: Sm...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  \\\n",
       "0   WHAT car is this!?\\nNntp-Posting-Host: rac3.w...      7   \n",
       "1   SI Clock Poll - Final Call\\nSummary: Final ca...      4   \n",
       "2   PB questions...\\nOrganization: Purdue Univers...      4   \n",
       "3   Re: Weitek P9000 ?\\nOrganization: Harris Comp...      1   \n",
       "4   Re: Shuttle Launch Question\\nOrganization: Sm...     14   \n",
       "\n",
       "              Class Name  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing function to training and test datasets\n",
    "df_train = preprocess_newsgroup_data(newsgroups_train)\n",
    "df_test = preprocess_newsgroup_data(newsgroups_test)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，您将通过在训练数据集中获取 100 个数据点并删除一些类别来对一些数据进行采样，以运行本教程。选择要比较的科学类别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(df, num_samples, classes_to_keep):\n",
    "  df = df.groupby('Label', as_index = False).apply(lambda x: x.sample(num_samples)).reset_index(drop=True)\n",
    "\n",
    "  df = df[df['Class Name'].str.contains(classes_to_keep)]\n",
    "\n",
    "  # Reset the encoding of the labels after sampling and dropping certain categories\n",
    "  df['Class Name'] = df['Class Name'].astype('category')\n",
    "  df['Encoded Label'] = df['Class Name'].cat.codes\n",
    "\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NUM_SAMPLES = 100\n",
    "TEST_NUM_SAMPLES = 25\n",
    "CLASSES_TO_KEEP = 'sci' # Class name should contain 'sci' in it to keep science categories\n",
    "df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Name\n",
       "sci.crypt          100\n",
       "sci.electronics    100\n",
       "sci.med            100\n",
       "sci.space          100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.value_counts('Class Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Name\n",
       "sci.crypt          25\n",
       "sci.electronics    25\n",
       "sci.med            25\n",
       "sci.space          25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.value_counts('Class Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建嵌入\n",
    "在本节中，您将了解如何使用 Gemini API 中的嵌入为一段文本生成嵌入。要了解有关嵌入的更多信息，请访问[嵌入指南](embeddings_guide.md)。\n",
    "```{tip}\n",
    "注意：嵌入一次计算一个，大样本量可能需要很长时间！\n",
    "```\n",
    "\n",
    "### 嵌入的 API 更改 embedding-001\n",
    "对于新的嵌入模型，有一个新的任务类型参数和可选标题（仅在 task_type=RETRIEVAL_DOCUMENT 时有效）。\n",
    "\n",
    "这些新参数仅适用于最新的嵌入模型。任务类型为：\n",
    "| 任务类型 | 描述 |\n",
    "|--- | --- |\n",
    "| RETRIEVAL_QUERY | 指定给定文本是搜索/检索设置中的查询。|\n",
    "| RETRIEVAL_DOCUMENT | 指定给定文本是搜索/检索设置中的文档。|\n",
    "| SEMANTIC_SIMILARITY | 指定给定文本将用于语义文本相似性 (STS)。|\n",
    "| CLASSIFICATION | 指定嵌入将用于分类。|\n",
    "| CLUSTERING | 指定嵌入将用于聚类。|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from google.api_core import retry\n",
    "\n",
    "def make_embed_text_fn(model):\n",
    "\n",
    "  @retry.Retry(timeout=300.0)\n",
    "  def embed_fn(text: str) -> list[float]:\n",
    "    # Set the task_type to CLASSIFICATION.\n",
    "    embedding = genai.embed_content(model=model,\n",
    "                                    content=text,\n",
    "                                    task_type=\"classification\")\n",
    "    return embedding['embedding']\n",
    "\n",
    "  return embed_fn\n",
    "\n",
    "def create_embeddings(model, df):\n",
    "  df['Embeddings'] = df['Text'].progress_apply(make_embed_text_fn(model))\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:35<00:00,  2.57it/s]\n",
      "100%|██████████| 100/100 [00:38<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "model = 'models/embedding-001'\n",
    "df_train = create_embeddings(model, df_train)\n",
    "df_test = create_embeddings(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Encoded Label</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>More technical details\\nOrganization: AT&amp;T Be...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.005982968, -0.024433807, -0.028595297, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>Subject: Re: Keeping Your Mouth Shut \\n \\nRepl...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.021684153, 0.023106724, -0.06751694, -0.053...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>Re: How do they know what keys to ask for? \\n...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0026794474, -0.012339441, -0.084823035, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>Re: Source of random bits on a Unix workstati...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0067265956, -0.06828294, -0.093188696, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>Marc VanHeyningen &lt;&gt;Re: More technical details...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.01643939, -0.016774608, -0.020152368, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label Class Name  \\\n",
       "1100   More technical details\\nOrganization: AT&T Be...     11  sci.crypt   \n",
       "1101  Subject: Re: Keeping Your Mouth Shut \\n \\nRepl...     11  sci.crypt   \n",
       "1102   Re: How do they know what keys to ask for? \\n...     11  sci.crypt   \n",
       "1103   Re: Source of random bits on a Unix workstati...     11  sci.crypt   \n",
       "1104  Marc VanHeyningen <>Re: More technical details...     11  sci.crypt   \n",
       "\n",
       "      Encoded Label                                         Embeddings  \n",
       "1100              0  [0.005982968, -0.024433807, -0.028595297, -0.0...  \n",
       "1101              0  [0.021684153, 0.023106724, -0.06751694, -0.053...  \n",
       "1102              0  [0.0026794474, -0.012339441, -0.084823035, -0....  \n",
       "1103              0  [0.0067265956, -0.06828294, -0.093188696, -0.0...  \n",
       "1104              0  [-0.01643939, -0.016774608, -0.020152368, -0.0...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建简单的分类模型\n",
    "在这里，您将定义一个具有一个隐藏层和一类概率输出的简单模型。预测将对应于一段文本是特定类别新闻的概率。当您构建模型时，Keras 会自动打乱数据点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classification_model(input_size: int, num_classes: int) -> keras.Model:\n",
    "  inputs = x = keras.Input(input_size)\n",
    "  x = layers.Dense(input_size, activation='relu')(x)\n",
    "  x = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "  return keras.Model(inputs=[inputs], outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 768)]             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 768)               590592    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 3076      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 593668 (2.26 MB)\n",
      "Trainable params: 593668 (2.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Derive the embedding size from the first training element.\n",
    "embedding_size = len(df_train['Embeddings'].iloc[0])\n",
    "\n",
    "# Give your model a different name, as you have already used the variable name 'model'\n",
    "classifier = build_classification_model(embedding_size, len(df_train['Class Name'].unique()))\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型对新闻组进行分类\n",
    "最后，您可以训练一个简单的模型。使用少量的 epoch 以避免过度拟合。第一个时期比其他时期花费的时间要长得多，因为嵌入只需要计算一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Split the x and y components of the train and validation subsets.\n",
    "y_train = df_train['Encoded Label']\n",
    "x_train = np.stack(df_train['Embeddings'])\n",
    "y_val = df_test['Encoded Label']\n",
    "x_val = np.stack(df_test['Embeddings'])\n",
    "\n",
    "# Train the model for the desired number of epochs.\n",
    "callback = keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\n",
    "\n",
    "history = classifier.fit(x=x_train,\n",
    "                         y=y_train,\n",
    "                         validation_data=(x_val, y_val),\n",
    "                         callbacks=[callback],\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         epochs=NUM_EPOCHS,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估模型性能\n",
    "使用 Keras `Model.evaluate`获取测试数据集上的损失和准确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.evaluate(x=x_val, y=y_val, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估模型性能的一种方法是可视化分类器性能。使用plot_history 查看各个时期的损失和准确性趋势。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  \"\"\"\n",
    "    Plotting training and validation learning curves.\n",
    "\n",
    "    Args:\n",
    "      history: model history with all the metric measures\n",
    "  \"\"\"\n",
    "  fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "  fig.set_size_inches(20, 8)\n",
    "\n",
    "  # Plot loss\n",
    "  ax1.set_title('Loss')\n",
    "  ax1.plot(history.history['loss'], label = 'train')\n",
    "  ax1.plot(history.history['val_loss'], label = 'test')\n",
    "  ax1.set_ylabel('Loss')\n",
    "\n",
    "  ax1.set_xlabel('Epoch')\n",
    "  ax1.legend(['Train', 'Validation'])\n",
    "\n",
    "  # Plot accuracy\n",
    "  ax2.set_title('Accuracy')\n",
    "  ax2.plot(history.history['accuracy'],  label = 'train')\n",
    "  ax2.plot(history.history['val_accuracy'], label = 'test')\n",
    "  ax2.set_ylabel('Accuracy')\n",
    "  ax2.set_xlabel('Epoch')\n",
    "  ax2.legend(['Train', 'Validation'])\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了测量损失和准确性之外，查看模型性能的另一种方法是使用混淆矩阵。混淆矩阵使您能够评估分类模型在准确性之外的性能。您可以看到错误分类的点被分类为哪些内容。为了构建这个多类分类问题的混淆矩阵，需要获取测试集中的实际值和预测值。\n",
    "\n",
    "首先使用`Model.predict()`为验证集中的每个示例生成预测类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = classifier.predict(x=x_val)\n",
    "y_hat = np.argmax(y_hat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = dict(zip(df_test['Class Name'], df_test['Encoded Label']))\n",
    "labels_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = skmetrics.confusion_matrix(y_val, y_hat)\n",
    "disp = skmetrics.ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=labels_dict.keys())\n",
    "disp.plot(xticks_rotation='vertical')\n",
    "plt.title('Confusion matrix for newsgroup test dataset');\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下一步\n",
    "要了解有关如何使用嵌入的更多信息，请查看可用的[示例](https://ai.google.dev/examples?keywords=embed)。  \n",
    "要了解如何使用 Gemini API 中的其他服务，请访问[Python 快速入门](python_quickstart.ipynb)。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python nb (gemini)",
   "language": "python",
   "name": "gemini"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
