{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨åµŒå…¥è®­ç»ƒæ–‡æœ¬åˆ†ç±»å™¨\n",
    "## æ¦‚è¿°\n",
    "åœ¨æœ¬ç¬”è®°æœ¬ä¸­ï¼Œæ‚¨å°†å­¦ä¹ ä½¿ç”¨ Gemini API ç”Ÿæˆçš„åµŒå…¥æ¥è®­ç»ƒæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥æ ¹æ®ä¸»é¢˜å¯¹ä¸åŒç±»å‹çš„æ–°é—»ç»„å¸–å­è¿›è¡Œåˆ†ç±»ã€‚\n",
    "\n",
    "åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæ‚¨å°†è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨æ¥é¢„æµ‹æ–°é—»ç»„å¸–å­å±äºå“ªä¸ªç±»åˆ«ã€‚\n",
    "\n",
    "## å‰ææ¡ä»¶\n",
    "æ‚¨å¯ä»¥åœ¨ Google Colab ä¸­è¿è¡Œæ­¤å¿«é€Ÿå…¥é—¨ã€‚ \n",
    "\n",
    "è¦åœ¨æ‚¨è‡ªå·±çš„å¼€å‘ç¯å¢ƒä¸­å®Œæˆæœ¬å¿«é€Ÿå…¥é—¨ï¼Œè¯·ç¡®ä¿æ‚¨çš„ç¯å¢ƒæ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š \n",
    "- Python 3.9+ \n",
    "- å®‰è£… jupyter ä»¥è¿è¡Œç¬”è®°æœ¬\n",
    "\n",
    "## å®‰è£…\n",
    "é¦–å…ˆï¼Œä¸‹è½½å¹¶å®‰è£… Gemini API Python åº“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google.generativeai in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (0.3.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google.generativeai) (0.4.0)\n",
      "Requirement already satisfied: google-auth in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google.generativeai) (2.25.2)\n",
      "Requirement already satisfied: google-api-core in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google.generativeai) (2.15.0)\n",
      "Requirement already satisfied: protobuf in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google.generativeai) (4.23.4)\n",
      "Requirement already satisfied: tqdm in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google.generativeai) (4.66.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-ai-generativelanguage==0.4.0->google.generativeai) (1.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-api-core->google.generativeai) (1.62.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-api-core->google.generativeai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-auth->google.generativeai) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-auth->google.generativeai) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-auth->google.generativeai) (4.9)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google.generativeai) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google.generativeai) (1.60.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth->google.generativeai) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install google.generativeai \n",
    "# keras tensorflow\n",
    "## !pip install -U -q google.colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tqdm\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import google.generativeai as genai\n",
    "import google.ai.generativelanguage as glm\n",
    "\n",
    "# Used to securely store your API key\n",
    "# from google.colab import userdata\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import layers\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import sklearn.metrics as skmetrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è·å– API å¯†é’¥\n",
    "åœ¨ä½¿ç”¨ Gemini API ä¹‹å‰ï¼Œæ‚¨å¿…é¡»å…ˆè·å– API å¯†é’¥ã€‚å¦‚æœæ‚¨è¿˜æ²¡æœ‰å¯†é’¥ï¼Œè¯·åœ¨ Google AI Studio ä¸­ä¸€é”®åˆ›å»ºå¯†é’¥ã€‚\n",
    "\n",
    "åœ¨ Colab ä¸­ï¼Œå°†å¯†é’¥æ·»åŠ åˆ°å·¦ä¾§é¢æ¿â€œğŸ”‘â€ä¸‹çš„ç§˜å¯†ç®¡ç†å™¨ä¸­ã€‚å°†å…¶å‘½åä¸º API_KEYã€‚ è·å¾— API å¯†é’¥åï¼Œå°†å…¶ä¼ é€’ç»™ SDKã€‚æ‚¨å¯ä»¥é€šè¿‡ä¸¤ç§æ–¹å¼æ‰§è¡Œæ­¤æ“ä½œï¼š\n",
    "- å°†å¯†é’¥æ”¾å…¥ GOOGLE_API_KEY ç¯å¢ƒå˜é‡ä¸­ï¼ˆSDK å°†è‡ªåŠ¨ä»é‚£é‡Œè·å–å®ƒï¼‰ã€‚\n",
    "- å°†å¯†é’¥ä¼ é€’ç»™ genai.configure(api_key=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "# GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
    "GOOGLE_API_KEY = \"AIzaSyBityeJag9WTYwuZ75VJvqn3I4kzRm1Omo\"\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "è¦ç‚¹ï¼šæ¥ä¸‹æ¥ï¼Œæ‚¨å°†é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ã€‚ä»»ä½•åµŒå…¥æ¨¡å‹éƒ½é€‚ç”¨äºæœ¬æ•™ç¨‹ï¼Œä½†å¯¹äºå®é™…åº”ç”¨ç¨‹åºï¼Œé€‰æ‹©ç‰¹å®šæ¨¡å‹å¹¶åšæŒä½¿ç”¨éå¸¸é‡è¦ã€‚ä¸åŒå‹å·çš„è¾“å‡ºäº’ä¸å…¼å®¹ã€‚\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'embedContent' in m.supported_generation_methods:\n",
    "    print(m.name)\n",
    "\n",
    "# for m in genai.list_models():\n",
    "#   if 'generateContent' in m.supported_generation_methods:\n",
    "#     print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ•°æ®é›†\n",
    "[20 ä¸ªæ–°é—»ç»„æ–‡æœ¬æ•°æ®é›†](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html)åŒ…å« 20 ä¸ªä¸»é¢˜çš„ 18,000 ä¸ªæ–°é—»ç»„å¸–å­ï¼Œåˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ä¹‹é—´çš„åˆ’åˆ†åŸºäºç‰¹å®šæ—¥æœŸä¹‹å‰å’Œä¹‹åå‘å¸ƒçš„æ¶ˆæ¯ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæ‚¨å°†ä½¿ç”¨è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†çš„å­é›†ã€‚æ‚¨å°†é¢„å¤„ç†æ•°æ®å¹¶å°†å…¶ç»„ç»‡åˆ° Pandas æ•°æ®æ¡†ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "# View list of class names for dataset\n",
    "newsgroups_train.target_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»¥ä¸‹æ˜¯è®­ç»ƒé›†ä¸­æ•°æ®ç‚¹çš„ç¤ºä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = newsgroups_train.data[0].index('Lines')\n",
    "print(newsgroups_train.data[0][idx:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æ‚¨å°†å¼€å§‹é¢„å¤„ç†æœ¬æ•™ç¨‹çš„æ•°æ®ã€‚åˆ é™¤ä»»ä½•æ•æ„Ÿä¿¡æ¯ï¼Œä¾‹å¦‚å§“åã€ç”µå­é‚®ä»¶æˆ–æ–‡æœ¬çš„å†—ä½™éƒ¨åˆ†ï¼ˆä¾‹å¦‚`â€œå‘ä»¶äººï¼šâ€`å’Œ`â€œ\\nä¸»é¢˜ï¼šâ€`ï¼‰ã€‚å°†ä¿¡æ¯ç»„ç»‡åˆ° Pandas æ•°æ®æ¡†ä¸­ï¼Œä½¿å…¶æ›´å…·å¯è¯»æ€§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_newsgroup_data(newsgroup_dataset):\n",
    "  # Apply functions to remove names, emails, and extraneous words from data points in newsgroups.data\n",
    "  newsgroup_dataset.data = [re.sub(r'[\\w\\.-]+@[\\w\\.-]+', '', d) for d in newsgroup_dataset.data] # Remove email\n",
    "  newsgroup_dataset.data = [re.sub(r\"\\([^()]*\\)\", \"\", d) for d in newsgroup_dataset.data] # Remove names\n",
    "  newsgroup_dataset.data = [d.replace(\"From: \", \"\") for d in newsgroup_dataset.data] # Remove \"From: \"\n",
    "  newsgroup_dataset.data = [d.replace(\"\\nSubject: \", \"\") for d in newsgroup_dataset.data] # Remove \"\\nSubject: \"\n",
    "\n",
    "  # Cut off each text entry after 5,000 characters\n",
    "  newsgroup_dataset.data = [d[0:5000] if len(d) > 5000 else d for d in newsgroup_dataset.data]\n",
    "\n",
    "  # Put data points into dataframe\n",
    "  df_processed = pd.DataFrame(newsgroup_dataset.data, columns=['Text'])\n",
    "  df_processed['Label'] = newsgroup_dataset.target\n",
    "  # Match label to target name index\n",
    "  df_processed['Class Name'] = ''\n",
    "  for idx, row in df_processed.iterrows():\n",
    "    df_processed.at[idx, 'Class Name'] = newsgroup_dataset.target_names[row['Label']]\n",
    "\n",
    "  return df_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHAT car is this!?\\nNntp-Posting-Host: rac3.w...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SI Clock Poll - Final Call\\nSummary: Final ca...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PB questions...\\nOrganization: Purdue Univers...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: Weitek P9000 ?\\nOrganization: Harris Comp...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: Shuttle Launch Question\\nOrganization: Sm...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  \\\n",
       "0   WHAT car is this!?\\nNntp-Posting-Host: rac3.w...      7   \n",
       "1   SI Clock Poll - Final Call\\nSummary: Final ca...      4   \n",
       "2   PB questions...\\nOrganization: Purdue Univers...      4   \n",
       "3   Re: Weitek P9000 ?\\nOrganization: Harris Comp...      1   \n",
       "4   Re: Shuttle Launch Question\\nOrganization: Sm...     14   \n",
       "\n",
       "              Class Name  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing function to training and test datasets\n",
    "df_train = preprocess_newsgroup_data(newsgroups_train)\n",
    "df_test = preprocess_newsgroup_data(newsgroups_test)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥ï¼Œæ‚¨å°†é€šè¿‡åœ¨è®­ç»ƒæ•°æ®é›†ä¸­è·å– 100 ä¸ªæ•°æ®ç‚¹å¹¶åˆ é™¤ä¸€äº›ç±»åˆ«æ¥å¯¹ä¸€äº›æ•°æ®è¿›è¡Œé‡‡æ ·ï¼Œä»¥è¿è¡Œæœ¬æ•™ç¨‹ã€‚é€‰æ‹©è¦æ¯”è¾ƒçš„ç§‘å­¦ç±»åˆ«ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(df, num_samples, classes_to_keep):\n",
    "  df = df.groupby('Label', as_index = False).apply(lambda x: x.sample(num_samples)).reset_index(drop=True)\n",
    "\n",
    "  df = df[df['Class Name'].str.contains(classes_to_keep)]\n",
    "\n",
    "  # Reset the encoding of the labels after sampling and dropping certain categories\n",
    "  df['Class Name'] = df['Class Name'].astype('category')\n",
    "  df['Encoded Label'] = df['Class Name'].cat.codes\n",
    "\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NUM_SAMPLES = 100\n",
    "TEST_NUM_SAMPLES = 25\n",
    "CLASSES_TO_KEEP = 'sci' # Class name should contain 'sci' in it to keep science categories\n",
    "df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Name\n",
       "sci.crypt          100\n",
       "sci.electronics    100\n",
       "sci.med            100\n",
       "sci.space          100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.value_counts('Class Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Name\n",
       "sci.crypt          25\n",
       "sci.electronics    25\n",
       "sci.med            25\n",
       "sci.space          25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.value_counts('Class Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆ›å»ºåµŒå…¥\n",
    "åœ¨æœ¬èŠ‚ä¸­ï¼Œæ‚¨å°†äº†è§£å¦‚ä½•ä½¿ç”¨ Gemini API ä¸­çš„åµŒå…¥ä¸ºä¸€æ®µæ–‡æœ¬ç”ŸæˆåµŒå…¥ã€‚è¦äº†è§£æœ‰å…³åµŒå…¥çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·è®¿é—®[åµŒå…¥æŒ‡å—](embeddings_guide.md)ã€‚\n",
    "```{tip}\n",
    "æ³¨æ„ï¼šåµŒå…¥ä¸€æ¬¡è®¡ç®—ä¸€ä¸ªï¼Œå¤§æ ·æœ¬é‡å¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´ï¼\n",
    "```\n",
    "\n",
    "### åµŒå…¥çš„ API æ›´æ”¹ embedding-001\n",
    "å¯¹äºæ–°çš„åµŒå…¥æ¨¡å‹ï¼Œæœ‰ä¸€ä¸ªæ–°çš„ä»»åŠ¡ç±»å‹å‚æ•°å’Œå¯é€‰æ ‡é¢˜ï¼ˆä»…åœ¨ task_type=RETRIEVAL_DOCUMENT æ—¶æœ‰æ•ˆï¼‰ã€‚\n",
    "\n",
    "è¿™äº›æ–°å‚æ•°ä»…é€‚ç”¨äºæœ€æ–°çš„åµŒå…¥æ¨¡å‹ã€‚ä»»åŠ¡ç±»å‹ä¸ºï¼š\n",
    "| ä»»åŠ¡ç±»å‹ | æè¿° |\n",
    "|--- | --- |\n",
    "| RETRIEVAL_QUERY | æŒ‡å®šç»™å®šæ–‡æœ¬æ˜¯æœç´¢/æ£€ç´¢è®¾ç½®ä¸­çš„æŸ¥è¯¢ã€‚|\n",
    "| RETRIEVAL_DOCUMENT | æŒ‡å®šç»™å®šæ–‡æœ¬æ˜¯æœç´¢/æ£€ç´¢è®¾ç½®ä¸­çš„æ–‡æ¡£ã€‚|\n",
    "| SEMANTIC_SIMILARITY | æŒ‡å®šç»™å®šæ–‡æœ¬å°†ç”¨äºè¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼æ€§ (STS)ã€‚|\n",
    "| CLASSIFICATION | æŒ‡å®šåµŒå…¥å°†ç”¨äºåˆ†ç±»ã€‚|\n",
    "| CLUSTERING | æŒ‡å®šåµŒå…¥å°†ç”¨äºèšç±»ã€‚|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from google.api_core import retry\n",
    "\n",
    "def make_embed_text_fn(model):\n",
    "\n",
    "  @retry.Retry(timeout=300.0)\n",
    "  def embed_fn(text: str) -> list[float]:\n",
    "    # Set the task_type to CLASSIFICATION.\n",
    "    embedding = genai.embed_content(model=model,\n",
    "                                    content=text,\n",
    "                                    task_type=\"classification\")\n",
    "    return embedding['embedding']\n",
    "\n",
    "  return embed_fn\n",
    "\n",
    "def create_embeddings(model, df):\n",
    "  df['Embeddings'] = df['Text'].progress_apply(make_embed_text_fn(model))\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [02:35<00:00,  2.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:38<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "model = 'models/embedding-001'\n",
    "df_train = create_embeddings(model, df_train)\n",
    "df_test = create_embeddings(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Encoded Label</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>More technical details\\nOrganization: AT&amp;T Be...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.005982968, -0.024433807, -0.028595297, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>Subject: Re: Keeping Your Mouth Shut \\n \\nRepl...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.021684153, 0.023106724, -0.06751694, -0.053...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>Re: How do they know what keys to ask for? \\n...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0026794474, -0.012339441, -0.084823035, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>Re: Source of random bits on a Unix workstati...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0067265956, -0.06828294, -0.093188696, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>Marc VanHeyningen &lt;&gt;Re: More technical details...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.01643939, -0.016774608, -0.020152368, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label Class Name  \\\n",
       "1100   More technical details\\nOrganization: AT&T Be...     11  sci.crypt   \n",
       "1101  Subject: Re: Keeping Your Mouth Shut \\n \\nRepl...     11  sci.crypt   \n",
       "1102   Re: How do they know what keys to ask for? \\n...     11  sci.crypt   \n",
       "1103   Re: Source of random bits on a Unix workstati...     11  sci.crypt   \n",
       "1104  Marc VanHeyningen <>Re: More technical details...     11  sci.crypt   \n",
       "\n",
       "      Encoded Label                                         Embeddings  \n",
       "1100              0  [0.005982968, -0.024433807, -0.028595297, -0.0...  \n",
       "1101              0  [0.021684153, 0.023106724, -0.06751694, -0.053...  \n",
       "1102              0  [0.0026794474, -0.012339441, -0.084823035, -0....  \n",
       "1103              0  [0.0067265956, -0.06828294, -0.093188696, -0.0...  \n",
       "1104              0  [-0.01643939, -0.016774608, -0.020152368, -0.0...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ„å»ºç®€å•çš„åˆ†ç±»æ¨¡å‹\n",
    "åœ¨è¿™é‡Œï¼Œæ‚¨å°†å®šä¹‰ä¸€ä¸ªå…·æœ‰ä¸€ä¸ªéšè—å±‚å’Œä¸€ç±»æ¦‚ç‡è¾“å‡ºçš„ç®€å•æ¨¡å‹ã€‚é¢„æµ‹å°†å¯¹åº”äºä¸€æ®µæ–‡æœ¬æ˜¯ç‰¹å®šç±»åˆ«æ–°é—»çš„æ¦‚ç‡ã€‚å½“æ‚¨æ„å»ºæ¨¡å‹æ—¶ï¼ŒKeras ä¼šè‡ªåŠ¨æ‰“ä¹±æ•°æ®ç‚¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classification_model(input_size: int, num_classes: int) -> keras.Model:\n",
    "  inputs = x = keras.Input(input_size)\n",
    "  x = layers.Dense(input_size, activation='relu')(x)\n",
    "  x = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "  return keras.Model(inputs=[inputs], outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 768)]             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 768)               590592    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 3076      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 593668 (2.26 MB)\n",
      "Trainable params: 593668 (2.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Derive the embedding size from the first training element.\n",
    "embedding_size = len(df_train['Embeddings'].iloc[0])\n",
    "\n",
    "# Give your model a different name, as you have already used the variable name 'model'\n",
    "classifier = build_classification_model(embedding_size, len(df_train['Class Name'].unique()))\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è®­ç»ƒæ¨¡å‹å¯¹æ–°é—»ç»„è¿›è¡Œåˆ†ç±»\n",
    "æœ€åï¼Œæ‚¨å¯ä»¥è®­ç»ƒä¸€ä¸ªç®€å•çš„æ¨¡å‹ã€‚ä½¿ç”¨å°‘é‡çš„ epoch ä»¥é¿å…è¿‡åº¦æ‹Ÿåˆã€‚ç¬¬ä¸€ä¸ªæ—¶æœŸæ¯”å…¶ä»–æ—¶æœŸèŠ±è´¹çš„æ—¶é—´è¦é•¿å¾—å¤šï¼Œå› ä¸ºåµŒå…¥åªéœ€è¦è®¡ç®—ä¸€æ¬¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Split the x and y components of the train and validation subsets.\n",
    "y_train = df_train['Encoded Label']\n",
    "x_train = np.stack(df_train['Embeddings'])\n",
    "y_val = df_test['Encoded Label']\n",
    "x_val = np.stack(df_test['Embeddings'])\n",
    "\n",
    "# Train the model for the desired number of epochs.\n",
    "callback = keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\n",
    "\n",
    "history = classifier.fit(x=x_train,\n",
    "                         y=y_train,\n",
    "                         validation_data=(x_val, y_val),\n",
    "                         callbacks=[callback],\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         epochs=NUM_EPOCHS,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¯„ä¼°æ¨¡å‹æ€§èƒ½\n",
    "ä½¿ç”¨ Keras `Model.evaluate`è·å–æµ‹è¯•æ•°æ®é›†ä¸Šçš„æŸå¤±å’Œå‡†ç¡®æ€§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.evaluate(x=x_val, y=y_val, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¯„ä¼°æ¨¡å‹æ€§èƒ½çš„ä¸€ç§æ–¹æ³•æ˜¯å¯è§†åŒ–åˆ†ç±»å™¨æ€§èƒ½ã€‚ä½¿ç”¨plot_history æŸ¥çœ‹å„ä¸ªæ—¶æœŸçš„æŸå¤±å’Œå‡†ç¡®æ€§è¶‹åŠ¿ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  \"\"\"\n",
    "    Plotting training and validation learning curves.\n",
    "\n",
    "    Args:\n",
    "      history: model history with all the metric measures\n",
    "  \"\"\"\n",
    "  fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "  fig.set_size_inches(20, 8)\n",
    "\n",
    "  # Plot loss\n",
    "  ax1.set_title('Loss')\n",
    "  ax1.plot(history.history['loss'], label = 'train')\n",
    "  ax1.plot(history.history['val_loss'], label = 'test')\n",
    "  ax1.set_ylabel('Loss')\n",
    "\n",
    "  ax1.set_xlabel('Epoch')\n",
    "  ax1.legend(['Train', 'Validation'])\n",
    "\n",
    "  # Plot accuracy\n",
    "  ax2.set_title('Accuracy')\n",
    "  ax2.plot(history.history['accuracy'],  label = 'train')\n",
    "  ax2.plot(history.history['val_accuracy'], label = 'test')\n",
    "  ax2.set_ylabel('Accuracy')\n",
    "  ax2.set_xlabel('Epoch')\n",
    "  ax2.legend(['Train', 'Validation'])\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é™¤äº†æµ‹é‡æŸå¤±å’Œå‡†ç¡®æ€§ä¹‹å¤–ï¼ŒæŸ¥çœ‹æ¨¡å‹æ€§èƒ½çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨æ··æ·†çŸ©é˜µã€‚æ··æ·†çŸ©é˜µä½¿æ‚¨èƒ½å¤Ÿè¯„ä¼°åˆ†ç±»æ¨¡å‹åœ¨å‡†ç¡®æ€§ä¹‹å¤–çš„æ€§èƒ½ã€‚æ‚¨å¯ä»¥çœ‹åˆ°é”™è¯¯åˆ†ç±»çš„ç‚¹è¢«åˆ†ç±»ä¸ºå“ªäº›å†…å®¹ã€‚ä¸ºäº†æ„å»ºè¿™ä¸ªå¤šç±»åˆ†ç±»é—®é¢˜çš„æ··æ·†çŸ©é˜µï¼Œéœ€è¦è·å–æµ‹è¯•é›†ä¸­çš„å®é™…å€¼å’Œé¢„æµ‹å€¼ã€‚\n",
    "\n",
    "é¦–å…ˆä½¿ç”¨`Model.predict()`ä¸ºéªŒè¯é›†ä¸­çš„æ¯ä¸ªç¤ºä¾‹ç”Ÿæˆé¢„æµ‹ç±»ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = classifier.predict(x=x_val)\n",
    "y_hat = np.argmax(y_hat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = dict(zip(df_test['Class Name'], df_test['Encoded Label']))\n",
    "labels_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = skmetrics.confusion_matrix(y_val, y_hat)\n",
    "disp = skmetrics.ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=labels_dict.keys())\n",
    "disp.plot(xticks_rotation='vertical')\n",
    "plt.title('Confusion matrix for newsgroup test dataset');\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸‹ä¸€æ­¥\n",
    "è¦äº†è§£æœ‰å…³å¦‚ä½•ä½¿ç”¨åµŒå…¥çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹å¯ç”¨çš„[ç¤ºä¾‹](https://ai.google.dev/examples?keywords=embed)ã€‚  \n",
    "è¦äº†è§£å¦‚ä½•ä½¿ç”¨ Gemini API ä¸­çš„å…¶ä»–æœåŠ¡ï¼Œè¯·è®¿é—®[Python å¿«é€Ÿå…¥é—¨](python_quickstart.ipynb)ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python nb (gemini)",
   "language": "python",
   "name": "gemini"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
