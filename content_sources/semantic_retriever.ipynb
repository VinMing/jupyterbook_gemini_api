{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语义检索\n",
    "\n",
    "![image](../statics/cost_pay.jpg)\n",
    "使用Google cloud 需要境外银行卡信息\n",
    "\n",
    "## 概述\n",
    "大型语言模型 (LLM) 无需直接接受训练即可学习新能力。然而，众所周知，LLM在回答他们未经培训的问题时会产生“幻觉”。部分原因是LLMs不知道训练后发生的事件。追踪LLM的回复来源也非常困难。对于可靠、可扩展的应用程序，LLM提供基于事实的答复并能够引用其信息来源非常重要。\n",
    "\n",
    "用于克服这些限制的常用方法称为检索增强生成（Retrieval Augmented Generation, RAG），它使用通过信息检索（Information Retrieval ,IR）机制从外部知识库检索的相关数据来增强发送给LLM的提示。知识库可以是您自己的文档、数据库或 API 语料库。\n",
    "\n",
    "本笔记本将引导您完成一个工作流程，通过使用外部文本语料库增强 LLM 的知识，并使用[Generative Language API](https://ai.google.dev/api/python/google/ai/generativelanguage) 的语义检索器和属性问答 (AQA) API 执行语义信息检索来回答问题，从而提高 LLM 的响应能力。\n",
    "\n",
    "```{tip}\n",
    "注意：该API目前处于测试阶段，仅在某些地区可用。\n",
    "```\n",
    "\n",
    "## 安装\n",
    "### 导入生成语言 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google.ai.generativelanguage in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google.ai.generativelanguage) (2.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google.ai.generativelanguage) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google.ai.generativelanguage) (4.23.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google.ai.generativelanguage) (1.62.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google.ai.generativelanguage) (2.25.2)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google.ai.generativelanguage) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google.ai.generativelanguage) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google.ai.generativelanguage) (1.60.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google.ai.generativelanguage) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google.ai.generativelanguage) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google.ai.generativelanguage) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google.ai.generativelanguage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google.ai.generativelanguage) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google.ai.generativelanguage) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google.ai.generativelanguage) (2023.11.17)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/st/miniconda3/envs/gemini/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google.ai.generativelanguage) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "# Install the Client library (Semantic Retriever is only supported for versions >0.4.0)\n",
    "!pip install google.ai.generativelanguage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 认证\n",
    "Semantic Retriever API 允许您对自己的数据执行语义搜索。由于这是您的数据，因此需要比 API 密钥更严格的访问控制。使用[服务帐户](https://ai.google.dev/docs/semantic_retriever#scrollTo=eLjhFIOQ7_Dk)或通过您的用户凭据进行[OAuth 身份验证](https://ai.google.dev/docs/semantic_retriever#scrollTo=9YGv4x9ehLba)。\n",
    "\n",
    "本快速入门使用适用于测试环境的简化身份验证方法，并且服务帐户设置通常更容易启动。对于生产环境，请先了解[身份验证和授权](https://developers.google.com/workspace/guides/auth-overview)，然后再选择适合您的应用程序的[访问凭据](https://developers.google.com/workspace/guides/create-credentials#choose_the_access_credential_that_is_right_for_you)。\n",
    "\n",
    "第一步，[启用生成语言 API](https://ai.google.dev/docs/oauth_quickstart#enable-api)。\n",
    "\n",
    "### 使用服务帐户设置 OAuth\n",
    "请按照以下步骤使用服务帐户设置 OAuth：  \n",
    "1. 按照[文档](https://developers.google.com/identity/protocols/oauth2/service-account#creatinganaccount)创建服务帐户。  \n",
    "        创建服务帐户后，生成服务帐户密钥。 \n",
    "2. 使用左侧边栏上的文件图标，然后使用上传图标上传您的服务帐户文件，如下面的屏幕截图所示。\n",
    "![image](../statics/colab_upload.png)\n",
    "\n",
    "```shell\n",
    "pip install -U google-auth-oauthlib\n",
    "```\n",
    "```python\n",
    "# Rename the uploaded file to `service_account_key.json` OR\n",
    "# Change the variable `service_account_file_name` in the code below.\n",
    "service_account_file_name = 'service_account_key.json'\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(service_account_file_name)\n",
    "\n",
    "scoped_credentials = credentials.with_scopes(\n",
    "    ['https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/generative-language.retriever'])\n",
    "\n",
    "```\n",
    "使用服务帐户凭据初始化客户端库。\n",
    "```python\n",
    "import google.ai.generativelanguage as glm\n",
    "generative_service_client = glm.GenerativeServiceClient(credentials=scoped_credentials)\n",
    "retriever_service_client = glm.RetrieverServiceClient(credentials=scoped_credentials)\n",
    "permission_service_client = glm.PermissionServiceClient(credentials=scoped_credentials)\n",
    "```\n",
    "\n",
    "### 使用用户凭据设置 OAuth\n",
    "按照[OAuth 快速入门](https://ai.google.dev/docs/oauth_quickstart)中的以下步骤设置 OAuth 身份验证。\n",
    "\n",
    "1. [配置 OAuth 同意屏幕。](https://ai.google.dev/docs/oauth_quickstart#configure-oauth)\n",
    "2. [授权桌面应用程序的凭据](https://ai.google.dev/docs/oauth_quickstart#authorize-credentials)。要在 Colab 中运行此笔记本，请首先将您的凭证文件（通常是`client_secret_*.json`）重命名为`client_secret.json`。然后使用左侧边栏上的文件图标上传文件，然后使用上传图标上传文件，如下面的屏幕截图所示。\n",
    "![image](../statics/colab_upload.png)\n",
    "```python\n",
    "# Replace TODO-your-project-name with the project used in the OAuth Quickstart\n",
    "project_name = \"TODO-your-project-name\" #  @param {type:\"string\"}\n",
    "# Replace TODO-your-email@gmail.com with the email added as a test user in the OAuth Quickstart\n",
    "email = \"TODO-your-email@gmail.com\" #  @param {type:\"string\"}\n",
    "# Rename the uploaded file to `client_secret.json` OR\n",
    "# Change the variable `client_file_name` in the code below.\n",
    "client_file_name = \"client_secret.json\"\n",
    "\n",
    "# IMPORTANT: Follow the instructions from the output - you must copy the command\n",
    "# to your terminal and copy the output after authentication back here.\n",
    "!gcloud config set project $project_name\n",
    "!gcloud config set account $email\n",
    "\n",
    "# NOTE: The simplified project setup in this tutorial triggers a \"Google hasn't verified this app.\" dialog.\n",
    "# This is normal, click \"Advanced\" -> \"Go to [app name] (unsafe)\"\n",
    "!gcloud auth application-default login --no-browser --client-id-file=$client_file_name --scopes=\"https://www.googleapis.com/auth/generative-language.retriever,https://www.googleapis.com/auth/cloud-platform\"\n",
    "\n",
    "```\n",
    "\n",
    "初始化客户端库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.ai.generativelanguage as glm\n",
    "\n",
    "generative_service_client = glm.GenerativeServiceClient()\n",
    "retriever_service_client = glm.RetrieverServiceClient()\n",
    "permission_service_client = glm.PermissionServiceClient()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建语料库\n",
    "Semantic Retriever API 允许您为每个项目定义最多 5 个自定义文本语料库。您可以在定义语料库时指定以下任一字段：\n",
    "- `name`：语料库资源名称 (ID)。最多只能包含 40 个字母数字字符。如果创建时名称为空，则将生成一个最大长度为 40 个字符的唯一名称，并带有来自 display_name 的前缀和 12 个字符的随机后缀。\n",
    "- `display_name`：语料库的人类可读的显示名称。最多只能包含 128 个字符，包括字母数字、空格和破折号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDenied",
     "evalue": "403 Request had insufficient authentication scopes. [reason: \"ACCESS_TOKEN_SCOPE_INSUFFICIENT\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\nmetadata {\n  key: \"method\"\n  value: \"google.ai.generativelanguage.v1beta.RetrieverService.CreateCorpus\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/gemini/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:79\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/gemini/lib/python3.10/site-packages/grpc/_channel.py:1160\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1154\u001b[0m (\n\u001b[1;32m   1155\u001b[0m     state,\n\u001b[1;32m   1156\u001b[0m     call,\n\u001b[1;32m   1157\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(\n\u001b[1;32m   1158\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1159\u001b[0m )\n\u001b[0;32m-> 1160\u001b[0m \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gemini/lib/python3.10/site-packages/grpc/_channel.py:1003\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1003\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.PERMISSION_DENIED\n\tdetails = \"Request had insufficient authentication scopes.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.250.69.202:443 {created_time:\"2023-12-22T14:18:46.650890513+08:00\", grpc_status:7, grpc_message:\"Request had insufficient authentication scopes.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/st/workspace/jupyter_book/tutorial_gemini_api/content_sources/semantic_retriever.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.6.35/home/st/workspace/jupyter_book/tutorial_gemini_api/content_sources/semantic_retriever.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m create_corpus_request \u001b[39m=\u001b[39m glm\u001b[39m.\u001b[39mCreateCorpusRequest(corpus\u001b[39m=\u001b[39mexample_corpus)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.6.35/home/st/workspace/jupyter_book/tutorial_gemini_api/content_sources/semantic_retriever.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Make the request\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.6.35/home/st/workspace/jupyter_book/tutorial_gemini_api/content_sources/semantic_retriever.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m create_corpus_response \u001b[39m=\u001b[39m retriever_service_client\u001b[39m.\u001b[39;49mcreate_corpus(create_corpus_request)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.6.35/home/st/workspace/jupyter_book/tutorial_gemini_api/content_sources/semantic_retriever.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Set the `corpus_resource_name` for subsequent sections.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.6.35/home/st/workspace/jupyter_book/tutorial_gemini_api/content_sources/semantic_retriever.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m corpus_resource_name \u001b[39m=\u001b[39m create_corpus_response\u001b[39m.\u001b[39mname\n",
      "File \u001b[0;32m~/miniconda3/envs/gemini/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/retriever_service/client.py:566\u001b[0m, in \u001b[0;36mRetrieverServiceClient.create_corpus\u001b[0;34m(self, request, corpus, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    563\u001b[0m rpc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport\u001b[39m.\u001b[39m_wrapped_methods[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport\u001b[39m.\u001b[39mcreate_corpus]\n\u001b[1;32m    565\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 566\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[1;32m    567\u001b[0m     request,\n\u001b[1;32m    568\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[1;32m    569\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    570\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    571\u001b[0m )\n\u001b[1;32m    573\u001b[0m \u001b[39m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/gemini/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gemini/lib/python3.10/site-packages/google/api_core/retry.py:372\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m target \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    369\u001b[0m sleep_generator \u001b[39m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    370\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maximum, multiplier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiplier\n\u001b[1;32m    371\u001b[0m )\n\u001b[0;32m--> 372\u001b[0m \u001b[39mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    373\u001b[0m     target,\n\u001b[1;32m    374\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predicate,\n\u001b[1;32m    375\u001b[0m     sleep_generator,\n\u001b[1;32m    376\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timeout,\n\u001b[1;32m    377\u001b[0m     on_error\u001b[39m=\u001b[39;49mon_error,\n\u001b[1;32m    378\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/gemini/lib/python3.10/site-packages/google/api_core/retry.py:207\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mfor\u001b[39;00m sleep \u001b[39min\u001b[39;00m sleep_generator:\n\u001b[1;32m    206\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m         result \u001b[39m=\u001b[39m target()\n\u001b[1;32m    208\u001b[0m         \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39misawaitable(result):\n\u001b[1;32m    209\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/miniconda3/envs/gemini/lib/python3.10/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout \u001b[39m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gemini/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:81\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mPermissionDenied\u001b[0m: 403 Request had insufficient authentication scopes. [reason: \"ACCESS_TOKEN_SCOPE_INSUFFICIENT\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\nmetadata {\n  key: \"method\"\n  value: \"google.ai.generativelanguage.v1beta.RetrieverService.CreateCorpus\"\n}\n]"
     ]
    }
   ],
   "source": [
    "example_corpus = glm.Corpus(display_name=\"Google for Developers Blog\")\n",
    "create_corpus_request = glm.CreateCorpusRequest(corpus=example_corpus)\n",
    "\n",
    "# Make the request\n",
    "create_corpus_response = retriever_service_client.create_corpus(create_corpus_request)\n",
    "\n",
    "# Set the `corpus_resource_name` for subsequent sections.\n",
    "corpus_resource_name = create_corpus_response.name\n",
    "print(create_corpus_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取创建的语料库\n",
    "使用`GetCorpusRequest`方法以编程方式访问您在上面创建的语料库。`name`参数的值是指语料库的完整资源名称，并在上面的单元格中设置为`corpus_resource_name`。预期格式为`corpora/corpus-123`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_corpus_request = glm.GetCorpusRequest(name=corpus_resource_name)\n",
    "\n",
    "# Make the request\n",
    "get_corpus_response = retriever_service_client.get_corpus(get_corpus_request)\n",
    "\n",
    "# Print the response\n",
    "print(get_corpus_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建文档\n",
    "一个语料库最多可以包含 10,000 个文档。您可以在定义文档时指定以下任一字段：\n",
    "- name：文档资源名称 (ID)。最多只能包含 40 个字符（仅限字母数字或破折号）。 ID 不能以破折号开头或结尾。如果创建时名称为空，则将从 display_name 派生出一个唯一名称以及 12 个字符的随机后缀。 \n",
    "- display_name：人类可读的显示名称。最多只能包含 512 个字符，包括字母数字、空格和破折号。\n",
    "`文档`还支持最多 20 个用户指定的`custom_metadata`字段，指定为键值对。自定义元数据可以是字符串、字符串列表或数字。请注意，字符串列表最多可支持 10 个值，并且数值在API中表示为浮点数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a document with a custom display name.\n",
    "example_document = glm.Document(display_name=\"Introducing Project IDX, An Experiment to Improve Full-stack, Multiplatform App Development\")\n",
    "\n",
    "# Add metadata.\n",
    "# Metadata also supports numeric values not specified here\n",
    "document_metadata = [\n",
    "    glm.CustomMetadata(key=\"url\", string_value=\"https://developers.googleblog.com/2023/08/introducing-project-idx-experiment-to-improve-full-stack-multiplatform-app-development.html\")]\n",
    "example_document.custom_metadata.extend(document_metadata)\n",
    "\n",
    "# Make the request\n",
    "# corpus_resource_name is a variable set in the \"Create a corpus\" section.\n",
    "create_corpus_request = glm.CreateDocumentRequest(parent=corpus_resource_name, document=example_document)\n",
    "create_document_response = retriever_service_client.create_document(create_corpus_request)\n",
    "\n",
    "# Set the `document_resource_name` for subsequent sections.\n",
    "document_resource_name = create_document_response.name\n",
    "print(create_document_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取创建的文档\n",
    "使用`GetDocumentRequest`方法以编程方式访问您在上面创建的文档。`name`参数的值是指文档的完整资源名称，并在上面的单元格中设置为`document_resource_name`。预期格式为`corpora/corpus-123/documents/document-123`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_document_request = glm.GetDocumentRequest(name=document_resource_name)\n",
    "\n",
    "# Make the request\n",
    "# document_resource_name is a variable set in the \"Create a document\" section.\n",
    "get_document_response = retriever_service_client.get_document(get_document_request)\n",
    "\n",
    "# Print the response\n",
    "print(get_document_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 摄取并分块文档\n",
    "为了提高语义检索期间矢量数据库返回的内容的相关性，请在摄取文档时将大文档分解为较小的片段或块。\n",
    "\n",
    "`Chunk`是`Document`的子部分，出于矢量表示和存储的目的，它被视为独立单元。一个`Chunk`最多可以有 2043 个`tokens`。一个语料库最多可以有 100 万个`Chunk`。\n",
    "\n",
    "与文档类似，块也支持最多 20 个用户指定的 custom_metadata 字段，指定为键值对。自定义元数据可以是字符串、字符串列表或数字。请注意，字符串列表最多可支持 10 个值，并且数值在 API 中表示为浮点数。\n",
    "\n",
    "本指南使用 Google 的[开源 HtmlChunker](https://github.com/google/labs-prototypes/tree/main/seeds/chunker-python)\n",
    "\n",
    "您可以使用的其他分块器包括[LangChain](https://python.langchain.com/docs/get_started/introduction)或 [LlamaIndex](https://www.llamaindex.ai/)。\n",
    "\n",
    "### 通过 HtmlChunker 摄取 HTML 和块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-labs-html-chunker\n",
    "\n",
    "from google_labs_html_chunker.html_chunker import HtmlChunker\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取网站的`HTML DOM`。在这里，直接读取HTML，但最好让`HTML`后渲染包含`Javascript`注入的 HTML，例如`document.documentElement.innerHTML`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with(urlopen(\"https://developers.googleblog.com/2023/08/introducing-project-idx-experiment-to-improve-full-stack-multiplatform-app-development.html\")) as f:\n",
    "  html = f.read().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将文本文档分解为段落并从这些段落创建块。此步骤创建`Chunk`对象本身，下一部分将它们上传到语义检索器 API。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk the file using HtmlChunker\n",
    "chunker = HtmlChunker(\n",
    "    max_words_per_aggregate_passage=200,\n",
    "    greedily_aggregate_sibling_nodes=True,\n",
    "    html_tags_to_exclude={\"noscript\", \"script\", \"style\"},\n",
    ")\n",
    "passages = chunker.chunk(html)\n",
    "print(passages)\n",
    "\n",
    "\n",
    "# Create `Chunk` entities.\n",
    "chunks = []\n",
    "for passage in passages:\n",
    "    chunk = glm.Chunk(data={'string_value': passage})\n",
    "    # Optionally, you can add metadata to a chunk\n",
    "    chunk.custom_metadata.append(glm.CustomMetadata(key=\"tags\",\n",
    "                                                    string_list_value=glm.StringList(\n",
    "                                                        values=[\"Google For Developers\", \"Project IDX\", \"Blog\", \"Announcement\"])))\n",
    "    chunk.custom_metadata.append(glm.CustomMetadata(key=\"chunking_strategy\",\n",
    "                                                    string_value=\"greedily_aggregate_sibling_nodes\"))\n",
    "    chunk.custom_metadata.append(glm.CustomMetadata(key = \"publish_date\",\n",
    "                                                    numeric_value = 20230808))\n",
    "    chunks.append(chunk)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 批量创建块\n",
    "批量创建块。您可以为每个批量请求指定最多 100 个块。 \n",
    "\n",
    "使用`CreateChunk()`创建单个块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Use HtmlChunker in the section above.\n",
    "# `chunks` is the variable set from the section above.\n",
    "create_chunk_requests = []\n",
    "for chunk in chunks:\n",
    "  create_chunk_requests.append(glm.CreateChunkRequest(parent=document_resource_name, chunk=chunk))\n",
    "\n",
    "# Make the request\n",
    "request = glm.BatchCreateChunksRequest(parent=document_resource_name, requests=create_chunk_requests)\n",
    "response = retriever_service_client.batch_create_chunks(request)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者，您可以在不使用 HtmlChunker 的情况下创建块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add up to 100 CreateChunk requests per batch request.\n",
    "# document_resource_name is a variable set in the \"Create a document\" section.\n",
    "chunks = []\n",
    "chunk_1 = glm.Chunk(data={'string_value': \"Chunks support user specified metadata.\"})\n",
    "chunk_1.custom_metadata.append(glm.CustomMetadata(key=\"section\",\n",
    "                                                  string_value=\"Custom metadata filters\"))\n",
    "chunk_2 = glm.Chunk(data={'string_value': \"The maximum number of metadata supported is 20\"})\n",
    "chunk_2.custom_metadata.append(glm.CustomMetadata(key = \"num_keys\",\n",
    "                                                  numeric_value = 20))\n",
    "chunks = [chunk_1, chunk_2]\n",
    "create_chunk_requests = []\n",
    "for chunk in chunks:\n",
    "  create_chunk_requests.append(glm.CreateChunkRequest(parent=document_resource_name, chunk=chunk))\n",
    "\n",
    "# Make the request\n",
    "request = glm.BatchCreateChunksRequest(parent=document_resource_name, requests=create_chunk_requests)\n",
    "response = retriever_service_client.batch_create_chunks(request)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 列出 chunk 并获取状态\n",
    "使用`ListChunksRequest`方法以分页列表的形式获取所有可用的`Chunks`，每页最大大小限制为 100 个`Chunks`，按 `Chunk.create_time`的升序排序。如果不指定限制，则最多返回 10 个`chunk`。\n",
    "\n",
    "提供 ListChunksRequest 响应中返回的 next_page_token 作为下一个请求的参数以检索下一页。请注意，分页时，提供给 ListChunks 的所有其他参数必须与提供页面令牌的调用相匹配。\n",
    "\n",
    "所有块都会返回一个状态。在查询语料库之前，使用它来检查块的状态。块状态包括 -`UNSPECIFIED`、`PENDING_PROCESSING`、`ACTIVE`和`FAILED`。您只能查询`ACTIVE` Chunks。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the request\n",
    "request = glm.ListChunksRequest(parent=document_resource_name)\n",
    "list_chunks_response = retriever_service_client.list_chunks(request)\n",
    "for index, chunks in enumerate(list_chunks_response.chunks):\n",
    "  print(f'\\nChunk # {index + 1}')\n",
    "  print(f'Resource Name: {chunks.name}')\n",
    "  # Only ACTIVE chunks can be queried.\n",
    "  print(f'State: {glm.Chunk.State(chunks.state).name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 摄取另一个文档\n",
    "通过 HtmlChunker 添加另一个文档并添加过滤器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a document with a custom display name.\n",
    "example_document = glm.Document(display_name=\"How it’s Made: Interacting with Gemini through multimodal prompting\")\n",
    "\n",
    "# Add document metadata.\n",
    "# Metadata also supports numeric values not specified here\n",
    "document_metadata = [\n",
    "    glm.CustomMetadata(key=\"url\", string_value=\"https://developers.googleblog.com/2023/12/how-its-made-gemini-multimodal-prompting.html\")]\n",
    "example_document.custom_metadata.extend(document_metadata)\n",
    "\n",
    "# Make the CreateDocument request\n",
    "# corpus_resource_name is a variable set in the \"Create a corpus\" section.\n",
    "create_document_request = glm.CreateDocumentRequest(parent=corpus_resource_name, document=example_document)\n",
    "create_document_response = retriever_service_client.create_document(create_document_request)\n",
    "\n",
    "# Set the `document_resource_name` for subsequent sections.\n",
    "document_resource_name = create_document_response.name\n",
    "print(create_document_response)\n",
    "\n",
    "# Chunks - add another webpage from Google for Developers\n",
    "with(urlopen(\"https://developers.googleblog.com/2023/12/how-its-made-gemini-multimodal-prompting.html\")) as f:\n",
    "  html = f.read().decode(\"utf-8\")\n",
    "\n",
    "# Chunk the file using HtmlChunker\n",
    "chunker = HtmlChunker(\n",
    "    max_words_per_aggregate_passage=100,\n",
    "    greedily_aggregate_sibling_nodes=False,\n",
    ")\n",
    "passages = chunker.chunk(html)\n",
    "\n",
    "# Create `Chunk` entities.\n",
    "chunks = []\n",
    "for passage in passages:\n",
    "    chunk = glm.Chunk(data={'string_value': passage})\n",
    "    chunk.custom_metadata.append(glm.CustomMetadata(key=\"tags\",\n",
    "                                                    string_list_value=glm.StringList(\n",
    "                                                        values=[\"Google For Developers\", \"Gemini API\", \"Blog\", \"Announcement\"])))\n",
    "    chunk.custom_metadata.append(glm.CustomMetadata(key=\"chunking_strategy\",\n",
    "                                                    string_value=\"no_aggregate_sibling_nodes\"))\n",
    "    chunk.custom_metadata.append(glm.CustomMetadata(key = \"publish_date\",\n",
    "                                                    numeric_value = 20231206))\n",
    "    chunks.append(chunk)\n",
    "\n",
    "# Make the request\n",
    "create_chunk_requests = []\n",
    "for chunk in chunks:\n",
    "  create_chunk_requests.append(glm.CreateChunkRequest(parent=document_resource_name, chunk=chunk))\n",
    "request = glm.BatchCreateChunksRequest(parent=document_resource_name, requests=create_chunk_requests)\n",
    "response = retriever_service_client.batch_create_chunks(request)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查询语料库\n",
    "使用`QueryCorpusRequest`方法执行语义搜索以获取相关段落。\n",
    "- results_count：指定要返回的段落数。最大值为 100。如果未指定，API 最多返回 10 个块。 \n",
    "- metadata_filters：按 chunk_metadata 或 document_metadata 过滤。每个MetadataFilter需要对应一个唯一的key。多个 MetadataFilter 对象通过逻辑 AND 连接。类似的元数据过滤条件通过逻辑 OR 连接。一些例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(year >= 2020 OR year < 2010) AND (genre = drama OR genre = action)\n",
    "\n",
    "metadata_filter = [\n",
    "  {\n",
    "    key = \"document.custom_metadata.year\"\n",
    "    conditions = [\n",
    "      {int_value = 2020, operation = GREATER_EQUAL},\n",
    "      {int_value = 2010, operation = LESS}]\n",
    "  },\n",
    "  {\n",
    "    key = \"document.custom_metadata.genre\"\n",
    "    conditions = [\n",
    "      {string_value = \"drama\", operation = EQUAL},\n",
    "      {string_value = \"action\", operation = EQUAL} }]\n",
    "  }]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，只有数字值支持同一键的“AND”。字符串值仅支持同一键的“OR”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\"Google for Developers\" in tags) and (20230314 > publish_date)\n",
    "\n",
    "metadata_filter = [{\n",
    "    key = \"chunk.custom_metadata.tags\",\n",
    "    conditions = [\n",
    "    {string_value = 'Google for Developers', operation = INCLUDES},\n",
    "  },{\n",
    "    key = \"chunk.custom_metadata.publish_date\",\n",
    "    conditions = [\n",
    "    {numeric_value = 20230314, operation = GREATER_EQUAL}]\n",
    "  }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What is the purpose of Project IDX?\"\n",
    "results_count = 5\n",
    "\n",
    "# Add metadata filters for both chunk and document.\n",
    "chunk_metadata_filter = glm.MetadataFilter(key='chunk.custom_metadata.tags',\n",
    "                                           conditions=[glm.Condition(\n",
    "                                              string_value='Google For Developers',\n",
    "                                              operation=glm.Condition.Operator.INCLUDES)])\n",
    "\n",
    "# Make the request\n",
    "# corpus_resource_name is a variable set in the \"Create a corpus\" section.\n",
    "request = glm.QueryCorpusRequest(name=corpus_resource_name,\n",
    "                                 query=user_query,\n",
    "                                 results_count=results_count,\n",
    "                                 metadata_filters=[chunk_metadata_filter])\n",
    "query_corpus_response = retriever_service_client.query_corpus(request)\n",
    "print(query_corpus_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 归因问答\n",
    "Attributed Question-Answering, AQA  \n",
    "使用GenerateAnswer 方法对文档、语料库或一组段落执行属性问答。   \n",
    "归因问答 (AQA) 是指回答基于给定上下文的问题并提供归因，同时最大限度地减少幻觉。\n",
    "\n",
    "在需要 AQA 的情况下，GenerateAnswer 比使用未调整的 LLM 具有多个优势：\n",
    "- 底层模型经过训练，只返回基于所提供上下文的答案。\n",
    "- 它识别归因（所提供的上下文中对答案有贡献的部分）。归因使用户能够验证答案。\n",
    "- 它估计给定（问题、上下文）对的answerable_probability，这进一步使您能够根据返回的答案的合理性和正确性来转移产品行为。\n",
    "\n",
    "### answerable_probability 和“我不知道”问题\n",
    "在某些情况下，对这个问题的最佳回答实际上是“我不知道”。例如，如果提供的上下文不包含问题的答案，则该问题被视为“无法回答”。\n",
    "\n",
    "AQA 模型非常擅长识别此类情况。它甚至可以区分可回答性和不可回答性的程度。\n",
    "\n",
    "然而，`GenerateAnswer`API 通过以下方式将最终决策权交给您：\n",
    "\n",
    "- 始终尝试返回一个有根据的答案 - 即使该答案相对不太可能有根据和正确。\n",
    "- 返回值`answerable_probability` - 模型对答案有根据且正确的概率的估计。\n",
    "\n",
    "低`answerable_probability`可能由以下 1 个或多个因素解释：\n",
    "- 该模型不确定其答案是否正确。\n",
    "- 该模型不确定其答案是否基于所引用的段落；答案可能是从世界知识中得出的。例如：`问题=“1+1=？”，段落=[“2+2=4”]`→`答案=2`，`answerable_probability=0.02`\n",
    "- 该模型提供了并未完全回答问题的相关信息。示例：`question=“我的尺码有吗？”，passages=[“尺码 5-11 有吗”]`→`answer=“是的，尺码有 5-11”`，`answerable_probability=0.03”`\n",
    "- 在GenerateAnswerRequest 中没有提出格式正确的问题。\n",
    "\n",
    "由于较低的`answerable_probability`表明GenerateAnswerResponse.answer可能是错误的或没有根据的，因此强烈建议通过检查`answerable_probability`来进一步处理响应。\n",
    "\n",
    "当`answerable_probability`较低时，一些客户可能希望：\n",
    "- 向最终用户显示一条消息，大意是“我们无法回答该问题”。\n",
    "- 回到通用的`LLM`，从世界知识中回答问题。此类回退的阈值和性质将取决于各个用例。`answerable_probability <= 0.5`的值是一个很好的起始阈值。\n",
    "\n",
    "### AQA 有用的提示\n",
    "有关完整的 API 规范，请参阅[GenerateAnswerRequest API 参考](https://ai.google.dev/api/python/google/ai/generativelanguage/GenerateAnswerRequest)。\n",
    "- 段落长度：建议每段最多 300 个令牌。\n",
    "- 段落排序：\n",
    "    - 如果您提供`GenerateAnswerRequest.inline_passages`，则应按与查询相关性的降序对段落进行排序。如果超出模型的上下文长度限制，则最后（最不相关）的段落将被省略。\n",
    "    - 如果您提供`GenerateAnswerRequest.semantic_retriever`，那么将自动为您完成相关性排序。\n",
    "- 局限性：AQA 模型专门用于问答。对于其他用例，例如创意写作、摘要等，请通过GenerateContent调用通用模型。\n",
    "    - 聊天：如果已知用户输入是可以从特定上下文中回答的问题，则 AQA 可以回答聊天查询。但如果用户输入可能是任何类型的条目，那么通用模型可能是更好的选择。\n",
    "- 温度\n",
    "    - 一般来说，为了获得准确的 AQA，建议使用相对较低的温度 (~0.2)。\n",
    "    - 如果您的用例依赖于确定性输出，则设置温度=0。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What is the purpose of Project IDX?\"\n",
    "answer_style = \"ABSTRACTIVE\" # Or VERBOSE, EXTRACTIVE\n",
    "MODEL_NAME = \"models/aqa\"\n",
    "\n",
    "# Make the request\n",
    "# corpus_resource_name is a variable set in the \"Create a corpus\" section.\n",
    "content = glm.Content(parts=[glm.Part(text=user_query)])\n",
    "retriever_config = glm.SemanticRetrieverConfig(source=corpus_resource_name, query=content)\n",
    "req = glm.GenerateAnswerRequest(model=MODEL_NAME,\n",
    "                                contents=[content],\n",
    "                                semantic_retriever=retriever_config,\n",
    "                                answer_style=answer_style)\n",
    "aqa_response = generative_service_client.generate_answer(req)\n",
    "print(aqa_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the metadata from the first attributed passages for the source\n",
    "chunk_resource_name = aqa_response.answer.grounding_attributions[0].source_id.semantic_retriever_chunk.chunk\n",
    "get_chunk_response = retriever_service_client.get_chunk(name=chunk_resource_name)\n",
    "print(get_chunk_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更多选项：使用内联通道的 AQA\n",
    "或者，您可以直接使用 AQA 端点，而无需通过传递 inline_passages 使用语义检索器 API。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What is AQA from Google?\"\n",
    "user_query_content = glm.Content(parts=[glm.Part(text=user_query)])\n",
    "answer_style = \"VERBOSE\" # or ABSTRACTIVE, EXTRACTIVE\n",
    "MODEL_NAME = \"models/aqa\"\n",
    "\n",
    "# Create the grounding inline passages\n",
    "grounding_passages = glm.GroundingPassages()\n",
    "passage_a = glm.Content(parts=[glm.Part(text=\"Attributed Question and Answering (AQA) refers to answering questions grounded to a given corpus and providing citation\")])\n",
    "grounding_passages.passages.append(glm.GroundingPassage(content=passage_a, id=\"001\"))\n",
    "passage_b = glm.Content(parts=[glm.Part(text=\"An LLM is not designed to generate content grounded in a set of passages. Although instructing an LLM to answer questions only based on a set of passages reduces hallucination, hallucination still often occurs when LLMs generate responses unsupported by facts provided by passages\")])\n",
    "grounding_passages.passages.append(glm.GroundingPassage(content=passage_b, id=\"002\"))\n",
    "passage_c = glm.Content(parts=[glm.Part(text=\"Hallucination is one of the biggest problems in Large Language Models (LLM) development. Large Language Models (LLMs) could produce responses that are fictitious and incorrect, which significantly impacts the usefulness and trustworthiness of applications built with language models.\")])\n",
    "grounding_passages.passages.append(glm.GroundingPassage(content=passage_c, id=\"003\"))\n",
    "\n",
    "# Create the request\n",
    "req = glm.GenerateAnswerRequest(model=MODEL_NAME,\n",
    "                                contents=[user_query_content],\n",
    "                                inline_passages=grounding_passages,\n",
    "                                answer_style=answer_style)\n",
    "aqa_response = generative_service_client.generate_answer(req)\n",
    "print(aqa_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分享语料库\n",
    "您可以选择使用 CreatePermissionRequest API 与其他人共享语料库。 \n",
    "限制条件：\n",
    "- 共享有 2 个角色：READER 和 EDITOR\n",
    "    - READER可以查询语料库。\n",
    "    - EDITOR拥有读者的权限，此外还可以编辑和共享语料库。 \n",
    "- 通过授予每个人 user_type 读取权限，可以公开语料库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace your-email@gmail.com with the email added as a test user in the OAuth Quickstart\n",
    "shared_user_email = \"TODO-your-email@gmail.com\" #  @param {type:\"string\"}\n",
    "user_type = \"USER\"\n",
    "role = \"READER\"\n",
    "\n",
    "# Make the request\n",
    "# corpus_resource_name is a variable set in the \"Create a corpus\" section.\n",
    "request = glm.CreatePermissionRequest(\n",
    "    parent=corpus_resource_name,\n",
    "    permission=glm.Permission(grantee_type=user_type,\n",
    "                              email_address=shared_user_email,\n",
    "                              role=role))\n",
    "create_permission_response = permission_service_client.create_permission(request)\n",
    "print(create_permission_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除语料库\n",
    "使用`DeleteCorpusRequest`删除用户语料库以及所有关联的文档和块。\n",
    "\n",
    "请注意，如果不指定`force=True`标志，非空语料库将引发错误。如果设置`force=True`，则与此`Document`相关的任何`Chunk`和对象也将被删除。\n",
    "\n",
    "如果`force=False`（默认值）并且文档包含任何块，则将返回`FAILED_PRECONDITION`错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set force to False if you don't want to delete non-empty corpora.\n",
    "req = glm.DeleteCorpusRequest(name=corpus_resource_name, force=True)\n",
    "delete_corpus_response = retriever_service_client.delete_corpus(req)\n",
    "print(\"Successfully deleted corpus: \" + corpus_resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结和进一步阅读\n",
    "本指南介绍了生成语言 API 的语义检索器和属性问答 (AQA) API，并展示了如何使用它对自定义文本数据执行语义信息检索。请注意，此 API 也适用于[LlamaIndex](https://www.llamaindex.ai/)数据框架。请参阅[LlamaIndex 教程](https://github.com/run-llama/llama_index/blob/main/docs/examples/managed/GoogleDemo.ipynb)以了解更多信息。\n",
    "\n",
    "另请参阅[API 文档](https://ai.google.dev/api)以了解有关其他可用功能的更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python nb (gemini)",
   "language": "python",
   "name": "gemini"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
